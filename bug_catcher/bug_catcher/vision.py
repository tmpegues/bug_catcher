"""
The script implements the Vision class for the 'bug_catcher' package.

It handles the low-level image processing tasks, including loading HSV calibration
data, generating binary masks for specific colors, detecting contours, and
tracking objects over time using the SORT algorithm.
"""

import cv2

import numpy as np

import yaml


class Vision:
    """
    Vision processing backend for color detection and object tracking.

    Attributes
    ----------
    blur_ksize (int): Kernel size for Gaussian blur to reduce noise.
    tracker (Sort): Instance of the SORT tracker for persistent object IDs.
    colors (dict): Dictionary storing HSV thresholds (low, high) for each color.

    """

    def __init__(self):
        """Initialize the Vision processor."""
        # Kernel size for blurring
        self.blur_ksize = 11

        # Dictionary to store loaded color profiles
        self.colors = {}

    def load_calibration(self, yaml_path):
        """
        Load color calibration data from a YAML file.

        Parses the file generated by the 'hsv_tuner' node and populates the
        internal colors dictionary.

        Args:
        ----
        yaml_path (str): Absolute path to the calibration YAML file.

        """
        print(f'Loading calibration from: {yaml_path}')
        with open(yaml_path, 'r') as f:
            data = yaml.safe_load(f)

        if data:
            for entry in data:
                name = entry['color']
                low = np.array(entry['hsv']['low'])
                high = np.array(entry['hsv']['high'])
                self.colors[name] = (low, high)
                print(f'Loaded color profile: {name}')

    def get_mask(self, frame, color_name):
        """
        Generate a binary mask for a specific color.

        Applies Gaussian blur, converts to HSV color space, thresholds the image
        based on calibrated values, and applies morphological operations to remove noise.

        Args:
        ----
        frame (np.ndarray): The input BGR video frame.
        color_name (str): The name of the color to mask (e.g., 'red').

        Returns
        -------
        mask (np.ndarray): Binary mask where white represents the target color.
                           Returns None if the color_name is not found.

        """
        if color_name not in self.colors:
            return None

        low_hsv, high_hsv = self.colors[color_name]

        # 1. Apply Gaussian Blur to reduce high-frequency noise
        blurred = cv2.GaussianBlur(frame, (self.blur_ksize, self.blur_ksize), 0)

        # 2. Convert from BGR to HSV color space
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # 3. Apply Thresholding
        mask = cv2.inRange(hsv, low_hsv, high_hsv)

        # 4. Morphological Operations
        # Open: Removes small white noise (Erosion followed by Dilation)
        # Close: Fills small black holes inside objects (Dilation followed by Erosion)
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

        return mask

    def detect_objects(self, frame, color_name):
        """
        Detect objects of a specific color within the frame.

        Finds external contours on the generated mask, filters them by area size,
        and prepares the bounding box data for the tracker.

        Args:
        ----
        frame (np.ndarray): The input video frame.
        color_name (str): The target color to detect.

        Returns
        -------
        detections (np.ndarray): Array of detections [x1, y1, x2, y2, score] for SORT.
        display_frame (np.ndarray): A copy of the frame with raw detection boxes drawn.

        """
        mask = self.get_mask(frame, color_name)

        # Prepare display frame
        display_frame = frame.copy()

        if mask is None:
            h, w = frame.shape[:2]
            blank_mask = np.zeros((h, w), dtype=np.uint8)
            return [], display_frame, blank_mask

        # Find external contours only (excludes nested contours)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if not contours:
            return [], display_frame, mask

        # Find the largest contour
        largest_contour = None
        max_area = 0

        for cnt in contours:
            area = cv2.contourArea(cnt)

            # Filter small noise
            if area < 500:
                continue

            # Check if this is the biggest one so far
            if area > max_area:
                max_area = area
                largest_contour = cnt

        # If we found a valid object
        if largest_contour is not None:
            # Draw the RAW contour in RED (to show what was detected)
            cv2.drawContours(display_frame, [largest_contour], -1, (0, 0, 255), 2)
            return [largest_contour], display_frame, mask

        return [], display_frame, mask

    def update_tracker(self, detections, frame):
        """
        Update the SORT tracker with new detections and visualize results.

        Associates current detections with existing tracks to assign persistent IDs.

        Args:
        ----
        detections (np.ndarray): Array of current frame detections.
        frame (np.ndarray): The frame to draw tracking visualizations on.

        Returns
        -------
        results (list): List of tuples [(track_id, center_x, center_y), ...].
        frame (np.ndarray): The frame with tracking bounding boxes and IDs drawn.

        """
        if len(detections) == 0:
            return [], frame

        # Get the contour passed from detect_objects
        cnt = detections[0]

        # 1. Calculate Center (Centroid) using Moments
        M = cv2.moments(cnt)
        if M['m00'] != 0:
            cx = int(M['m10'] / M['m00'])
            cy = int(M['m01'] / M['m00'])
        else:
            # Fallback to bounding rect center if moments fail
            x, y, w, h = cv2.boundingRect(cnt)
            cx = int(x + w / 2)
            cy = int(y + h / 2)

        # 2. Assign a static ID (since we assume single object)
        obj_id = 0

        # 3. Visualization
        # Draw the contour in GREEN
        cv2.drawContours(frame, [cnt], -1, (0, 255, 0), 3)

        # Draw the Center Point
        cv2.circle(frame, (cx, cy), 7, (255, 0, 0), -1)  # Blue dot
        cv2.circle(frame, (cx, cy), 3, (255, 255, 255), -1)  # White inner dot

        # Draw ID
        cv2.putText(
            frame,
            f'Target (ID:{obj_id})',
            (cx - 20, cy - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2,
        )

        results = [(obj_id, cx, cy)]
        return results, frame
